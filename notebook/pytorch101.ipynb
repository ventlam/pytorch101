{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(28*28,512),nn.ReLU(),nn.Linear(512,512),nn.ReLU(),nn.Linear(512,10),nn.ReLU())\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)\n",
    "\n",
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        X,y  = X.to(device),y.to(device)\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 ==0 :\n",
    "            loss,current = loss.item(),batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader,model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss,correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss  += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)== y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.581136  [    0/60000]\n",
      "loss: 1.578499  [ 6400/60000]\n",
      "loss: 1.388895  [12800/60000]\n",
      "loss: 1.443964  [19200/60000]\n",
      "loss: 1.454681  [25600/60000]\n",
      "loss: 1.535340  [32000/60000]\n",
      "loss: 1.357982  [38400/60000]\n",
      "loss: 1.398639  [44800/60000]\n",
      "loss: 1.518858  [51200/60000]\n",
      "loss: 1.410977  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 1.419901 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.476831  [    0/60000]\n",
      "loss: 1.487324  [ 6400/60000]\n",
      "loss: 1.282590  [12800/60000]\n",
      "loss: 1.344944  [19200/60000]\n",
      "loss: 1.355325  [25600/60000]\n",
      "loss: 1.455056  [32000/60000]\n",
      "loss: 1.269731  [38400/60000]\n",
      "loss: 1.323484  [44800/60000]\n",
      "loss: 1.440022  [51200/60000]\n",
      "loss: 1.342420  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 1.345454 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.398685  [    0/60000]\n",
      "loss: 1.421350  [ 6400/60000]\n",
      "loss: 1.204431  [12800/60000]\n",
      "loss: 1.271617  [19200/60000]\n",
      "loss: 1.285724  [25600/60000]\n",
      "loss: 1.394904  [32000/60000]\n",
      "loss: 1.208167  [38400/60000]\n",
      "loss: 1.270168  [44800/60000]\n",
      "loss: 1.381521  [51200/60000]\n",
      "loss: 1.292779  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 1.291596 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.338642  [    0/60000]\n",
      "loss: 1.370603  [ 6400/60000]\n",
      "loss: 1.145104  [12800/60000]\n",
      "loss: 1.216821  [19200/60000]\n",
      "loss: 1.236547  [25600/60000]\n",
      "loss: 1.349236  [32000/60000]\n",
      "loss: 1.163740  [38400/60000]\n",
      "loss: 1.231361  [44800/60000]\n",
      "loss: 1.336623  [51200/60000]\n",
      "loss: 1.255382  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.251268 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.291037  [    0/60000]\n",
      "loss: 1.331941  [ 6400/60000]\n",
      "loss: 1.100104  [12800/60000]\n",
      "loss: 1.176000  [19200/60000]\n",
      "loss: 1.200480  [25600/60000]\n",
      "loss: 1.313874  [32000/60000]\n",
      "loss: 1.129326  [38400/60000]\n",
      "loss: 1.202579  [44800/60000]\n",
      "loss: 1.300737  [51200/60000]\n",
      "loss: 1.226568  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 1.219785 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.252372  [    0/60000]\n",
      "loss: 1.300921  [ 6400/60000]\n",
      "loss: 1.064537  [12800/60000]\n",
      "loss: 1.144474  [19200/60000]\n",
      "loss: 1.172795  [25600/60000]\n",
      "loss: 1.286185  [32000/60000]\n",
      "loss: 1.101718  [38400/60000]\n",
      "loss: 1.180088  [44800/60000]\n",
      "loss: 1.270526  [51200/60000]\n",
      "loss: 1.202757  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.194119 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.219635  [    0/60000]\n",
      "loss: 1.275279  [ 6400/60000]\n",
      "loss: 1.035117  [12800/60000]\n",
      "loss: 1.119475  [19200/60000]\n",
      "loss: 1.150561  [25600/60000]\n",
      "loss: 1.263570  [32000/60000]\n",
      "loss: 1.078907  [38400/60000]\n",
      "loss: 1.162020  [44800/60000]\n",
      "loss: 1.244356  [51200/60000]\n",
      "loss: 1.182655  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.172386 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.190710  [    0/60000]\n",
      "loss: 1.252895  [ 6400/60000]\n",
      "loss: 1.010187  [12800/60000]\n",
      "loss: 1.099063  [19200/60000]\n",
      "loss: 1.132587  [25600/60000]\n",
      "loss: 1.244209  [32000/60000]\n",
      "loss: 1.058911  [38400/60000]\n",
      "loss: 1.146187  [44800/60000]\n",
      "loss: 1.220878  [51200/60000]\n",
      "loss: 1.164836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.153368 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.165077  [    0/60000]\n",
      "loss: 1.232382  [ 6400/60000]\n",
      "loss: 0.988342  [12800/60000]\n",
      "loss: 1.082289  [19200/60000]\n",
      "loss: 1.116473  [25600/60000]\n",
      "loss: 1.227268  [32000/60000]\n",
      "loss: 1.041638  [38400/60000]\n",
      "loss: 1.132529  [44800/60000]\n",
      "loss: 1.199143  [51200/60000]\n",
      "loss: 1.148525  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.136264 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.141524  [    0/60000]\n",
      "loss: 1.213602  [ 6400/60000]\n",
      "loss: 0.968619  [12800/60000]\n",
      "loss: 1.068002  [19200/60000]\n",
      "loss: 1.102077  [25600/60000]\n",
      "loss: 1.211962  [32000/60000]\n",
      "loss: 1.025400  [38400/60000]\n",
      "loss: 1.120095  [44800/60000]\n",
      "loss: 1.179462  [51200/60000]\n",
      "loss: 1.133578  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.120586 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.119590  [    0/60000]\n",
      "loss: 1.195086  [ 6400/60000]\n",
      "loss: 0.950653  [12800/60000]\n",
      "loss: 1.055699  [19200/60000]\n",
      "loss: 1.088616  [25600/60000]\n",
      "loss: 1.197755  [32000/60000]\n",
      "loss: 1.010533  [38400/60000]\n",
      "loss: 1.108726  [44800/60000]\n",
      "loss: 1.161163  [51200/60000]\n",
      "loss: 1.119688  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.106066 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.099211  [    0/60000]\n",
      "loss: 1.177941  [ 6400/60000]\n",
      "loss: 0.933961  [12800/60000]\n",
      "loss: 1.044986  [19200/60000]\n",
      "loss: 1.077065  [25600/60000]\n",
      "loss: 1.184838  [32000/60000]\n",
      "loss: 0.996580  [38400/60000]\n",
      "loss: 1.098290  [44800/60000]\n",
      "loss: 1.143874  [51200/60000]\n",
      "loss: 1.106732  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 1.092521 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.079817  [    0/60000]\n",
      "loss: 1.162061  [ 6400/60000]\n",
      "loss: 0.918945  [12800/60000]\n",
      "loss: 1.035384  [19200/60000]\n",
      "loss: 1.066610  [25600/60000]\n",
      "loss: 1.172935  [32000/60000]\n",
      "loss: 0.983544  [38400/60000]\n",
      "loss: 1.088886  [44800/60000]\n",
      "loss: 1.128053  [51200/60000]\n",
      "loss: 1.094573  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 1.079853 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.061919  [    0/60000]\n",
      "loss: 1.147372  [ 6400/60000]\n",
      "loss: 0.905134  [12800/60000]\n",
      "loss: 1.026804  [19200/60000]\n",
      "loss: 1.057168  [25600/60000]\n",
      "loss: 1.162188  [32000/60000]\n",
      "loss: 0.971341  [38400/60000]\n",
      "loss: 1.080194  [44800/60000]\n",
      "loss: 1.113865  [51200/60000]\n",
      "loss: 1.082717  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 1.068005 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.045498  [    0/60000]\n",
      "loss: 1.133539  [ 6400/60000]\n",
      "loss: 0.892502  [12800/60000]\n",
      "loss: 1.019094  [19200/60000]\n",
      "loss: 1.049035  [25600/60000]\n",
      "loss: 1.152191  [32000/60000]\n",
      "loss: 0.959826  [38400/60000]\n",
      "loss: 1.072401  [44800/60000]\n",
      "loss: 1.100968  [51200/60000]\n",
      "loss: 1.071668  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 1.056914 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.030420  [    0/60000]\n",
      "loss: 1.120666  [ 6400/60000]\n",
      "loss: 0.880931  [12800/60000]\n",
      "loss: 1.012097  [19200/60000]\n",
      "loss: 1.041917  [25600/60000]\n",
      "loss: 1.143000  [32000/60000]\n",
      "loss: 0.949143  [38400/60000]\n",
      "loss: 1.065447  [44800/60000]\n",
      "loss: 1.089390  [51200/60000]\n",
      "loss: 1.060902  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.046501 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.016568  [    0/60000]\n",
      "loss: 1.108635  [ 6400/60000]\n",
      "loss: 0.870369  [12800/60000]\n",
      "loss: 1.005700  [19200/60000]\n",
      "loss: 1.035078  [25600/60000]\n",
      "loss: 1.134329  [32000/60000]\n",
      "loss: 0.939014  [38400/60000]\n",
      "loss: 1.058892  [44800/60000]\n",
      "loss: 1.079025  [51200/60000]\n",
      "loss: 1.050552  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 1.036738 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.003792  [    0/60000]\n",
      "loss: 1.097208  [ 6400/60000]\n",
      "loss: 0.860553  [12800/60000]\n",
      "loss: 0.999492  [19200/60000]\n",
      "loss: 1.028970  [25600/60000]\n",
      "loss: 1.125920  [32000/60000]\n",
      "loss: 0.929737  [38400/60000]\n",
      "loss: 1.052859  [44800/60000]\n",
      "loss: 1.069191  [51200/60000]\n",
      "loss: 1.040609  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.027531 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.991938  [    0/60000]\n",
      "loss: 1.086717  [ 6400/60000]\n",
      "loss: 0.851542  [12800/60000]\n",
      "loss: 0.993486  [19200/60000]\n",
      "loss: 1.023723  [25600/60000]\n",
      "loss: 1.118492  [32000/60000]\n",
      "loss: 0.921419  [38400/60000]\n",
      "loss: 1.047445  [44800/60000]\n",
      "loss: 1.061162  [51200/60000]\n",
      "loss: 1.030759  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.018806 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.980990  [    0/60000]\n",
      "loss: 1.076735  [ 6400/60000]\n",
      "loss: 0.843427  [12800/60000]\n",
      "loss: 0.987768  [19200/60000]\n",
      "loss: 1.018215  [25600/60000]\n",
      "loss: 1.111834  [32000/60000]\n",
      "loss: 0.913518  [38400/60000]\n",
      "loss: 1.042664  [44800/60000]\n",
      "loss: 1.053980  [51200/60000]\n",
      "loss: 1.021311  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 1.010537 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.970868  [    0/60000]\n",
      "loss: 1.067396  [ 6400/60000]\n",
      "loss: 0.836103  [12800/60000]\n",
      "loss: 0.982300  [19200/60000]\n",
      "loss: 1.012876  [25600/60000]\n",
      "loss: 1.105282  [32000/60000]\n",
      "loss: 0.906122  [38400/60000]\n",
      "loss: 1.038728  [44800/60000]\n",
      "loss: 1.047425  [51200/60000]\n",
      "loss: 1.012122  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.002683 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.961295  [    0/60000]\n",
      "loss: 1.058649  [ 6400/60000]\n",
      "loss: 0.828999  [12800/60000]\n",
      "loss: 0.977215  [19200/60000]\n",
      "loss: 1.008088  [25600/60000]\n",
      "loss: 1.099571  [32000/60000]\n",
      "loss: 0.899284  [38400/60000]\n",
      "loss: 1.034805  [44800/60000]\n",
      "loss: 1.041648  [51200/60000]\n",
      "loss: 1.003139  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.995245 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.952516  [    0/60000]\n",
      "loss: 1.050349  [ 6400/60000]\n",
      "loss: 0.822281  [12800/60000]\n",
      "loss: 0.972249  [19200/60000]\n",
      "loss: 1.003145  [25600/60000]\n",
      "loss: 1.093852  [32000/60000]\n",
      "loss: 0.892803  [38400/60000]\n",
      "loss: 1.031168  [44800/60000]\n",
      "loss: 1.036802  [51200/60000]\n",
      "loss: 0.994527  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.988128 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.944351  [    0/60000]\n",
      "loss: 1.042578  [ 6400/60000]\n",
      "loss: 0.816180  [12800/60000]\n",
      "loss: 0.967440  [19200/60000]\n",
      "loss: 0.998472  [25600/60000]\n",
      "loss: 1.088498  [32000/60000]\n",
      "loss: 0.886831  [38400/60000]\n",
      "loss: 1.027882  [44800/60000]\n",
      "loss: 1.032220  [51200/60000]\n",
      "loss: 0.986040  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.981349 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.936659  [    0/60000]\n",
      "loss: 1.035053  [ 6400/60000]\n",
      "loss: 0.810280  [12800/60000]\n",
      "loss: 0.962911  [19200/60000]\n",
      "loss: 0.994125  [25600/60000]\n",
      "loss: 1.083742  [32000/60000]\n",
      "loss: 0.881330  [38400/60000]\n",
      "loss: 1.025253  [44800/60000]\n",
      "loss: 1.028331  [51200/60000]\n",
      "loss: 0.977690  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.974918 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.928712  [    0/60000]\n",
      "loss: 1.028095  [ 6400/60000]\n",
      "loss: 0.804750  [12800/60000]\n",
      "loss: 0.958425  [19200/60000]\n",
      "loss: 0.989629  [25600/60000]\n",
      "loss: 1.078888  [32000/60000]\n",
      "loss: 0.875901  [38400/60000]\n",
      "loss: 1.022506  [44800/60000]\n",
      "loss: 1.024804  [51200/60000]\n",
      "loss: 0.969429  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.968806 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.921060  [    0/60000]\n",
      "loss: 1.021369  [ 6400/60000]\n",
      "loss: 0.799859  [12800/60000]\n",
      "loss: 0.954180  [19200/60000]\n",
      "loss: 0.985524  [25600/60000]\n",
      "loss: 1.074340  [32000/60000]\n",
      "loss: 0.870920  [38400/60000]\n",
      "loss: 1.020066  [44800/60000]\n",
      "loss: 1.021606  [51200/60000]\n",
      "loss: 0.961594  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.963007 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.913773  [    0/60000]\n",
      "loss: 1.014795  [ 6400/60000]\n",
      "loss: 0.795256  [12800/60000]\n",
      "loss: 0.950040  [19200/60000]\n",
      "loss: 0.981437  [25600/60000]\n",
      "loss: 1.069373  [32000/60000]\n",
      "loss: 0.866146  [38400/60000]\n",
      "loss: 1.018092  [44800/60000]\n",
      "loss: 1.018691  [51200/60000]\n",
      "loss: 0.953990  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.957531 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.906545  [    0/60000]\n",
      "loss: 1.008673  [ 6400/60000]\n",
      "loss: 0.790957  [12800/60000]\n",
      "loss: 0.946014  [19200/60000]\n",
      "loss: 0.977791  [25600/60000]\n",
      "loss: 1.064361  [32000/60000]\n",
      "loss: 0.861991  [38400/60000]\n",
      "loss: 1.015468  [44800/60000]\n",
      "loss: 1.016196  [51200/60000]\n",
      "loss: 0.946604  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.952351 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.899695  [    0/60000]\n",
      "loss: 1.002863  [ 6400/60000]\n",
      "loss: 0.786940  [12800/60000]\n",
      "loss: 0.942129  [19200/60000]\n",
      "loss: 0.974500  [25600/60000]\n",
      "loss: 1.059614  [32000/60000]\n",
      "loss: 0.857422  [38400/60000]\n",
      "loss: 1.013548  [44800/60000]\n",
      "loss: 1.013662  [51200/60000]\n",
      "loss: 0.939386  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.947460 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.893279  [    0/60000]\n",
      "loss: 0.997436  [ 6400/60000]\n",
      "loss: 0.783032  [12800/60000]\n",
      "loss: 0.938185  [19200/60000]\n",
      "loss: 0.971007  [25600/60000]\n",
      "loss: 1.054949  [32000/60000]\n",
      "loss: 0.853577  [38400/60000]\n",
      "loss: 1.011916  [44800/60000]\n",
      "loss: 1.011753  [51200/60000]\n",
      "loss: 0.932388  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.942857 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.887085  [    0/60000]\n",
      "loss: 0.992295  [ 6400/60000]\n",
      "loss: 0.779560  [12800/60000]\n",
      "loss: 0.933595  [19200/60000]\n",
      "loss: 0.967257  [25600/60000]\n",
      "loss: 1.050460  [32000/60000]\n",
      "loss: 0.849718  [38400/60000]\n",
      "loss: 1.010549  [44800/60000]\n",
      "loss: 1.009997  [51200/60000]\n",
      "loss: 0.925600  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.938526 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.881118  [    0/60000]\n",
      "loss: 0.987540  [ 6400/60000]\n",
      "loss: 0.776149  [12800/60000]\n",
      "loss: 0.929154  [19200/60000]\n",
      "loss: 0.963753  [25600/60000]\n",
      "loss: 1.046307  [32000/60000]\n",
      "loss: 0.845912  [38400/60000]\n",
      "loss: 1.008746  [44800/60000]\n",
      "loss: 1.008052  [51200/60000]\n",
      "loss: 0.918944  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.934456 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.875398  [    0/60000]\n",
      "loss: 0.983232  [ 6400/60000]\n",
      "loss: 0.772967  [12800/60000]\n",
      "loss: 0.924863  [19200/60000]\n",
      "loss: 0.960371  [25600/60000]\n",
      "loss: 1.042392  [32000/60000]\n",
      "loss: 0.842340  [38400/60000]\n",
      "loss: 1.008295  [44800/60000]\n",
      "loss: 1.006329  [51200/60000]\n",
      "loss: 0.912766  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.930648 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.869905  [    0/60000]\n",
      "loss: 0.979227  [ 6400/60000]\n",
      "loss: 0.769878  [12800/60000]\n",
      "loss: 0.920765  [19200/60000]\n",
      "loss: 0.956962  [25600/60000]\n",
      "loss: 1.038618  [32000/60000]\n",
      "loss: 0.839011  [38400/60000]\n",
      "loss: 1.006629  [44800/60000]\n",
      "loss: 1.004797  [51200/60000]\n",
      "loss: 0.906724  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.927112 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.864659  [    0/60000]\n",
      "loss: 0.975368  [ 6400/60000]\n",
      "loss: 0.767075  [12800/60000]\n",
      "loss: 0.916740  [19200/60000]\n",
      "loss: 0.953620  [25600/60000]\n",
      "loss: 1.034812  [32000/60000]\n",
      "loss: 0.835904  [38400/60000]\n",
      "loss: 1.005004  [44800/60000]\n",
      "loss: 1.003305  [51200/60000]\n",
      "loss: 0.900934  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.923759 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.859518  [    0/60000]\n",
      "loss: 0.971427  [ 6400/60000]\n",
      "loss: 0.764139  [12800/60000]\n",
      "loss: 0.912521  [19200/60000]\n",
      "loss: 0.837277  [25600/60000]\n",
      "loss: 0.996407  [32000/60000]\n",
      "loss: 0.747822  [38400/60000]\n",
      "loss: 0.903304  [44800/60000]\n",
      "loss: 0.908370  [51200/60000]\n",
      "loss: 0.888862  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.847926 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.726113  [    0/60000]\n",
      "loss: 0.845638  [ 6400/60000]\n",
      "loss: 0.702567  [12800/60000]\n",
      "loss: 0.910574  [19200/60000]\n",
      "loss: 0.777325  [25600/60000]\n",
      "loss: 0.967960  [32000/60000]\n",
      "loss: 0.717727  [38400/60000]\n",
      "loss: 0.889069  [44800/60000]\n",
      "loss: 0.878225  [51200/60000]\n",
      "loss: 0.863776  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.823657 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.694451  [    0/60000]\n",
      "loss: 0.818540  [ 6400/60000]\n",
      "loss: 0.687017  [12800/60000]\n",
      "loss: 0.899803  [19200/60000]\n",
      "loss: 0.751505  [25600/60000]\n",
      "loss: 0.944024  [32000/60000]\n",
      "loss: 0.697135  [38400/60000]\n",
      "loss: 0.879472  [44800/60000]\n",
      "loss: 0.854141  [51200/60000]\n",
      "loss: 0.840408  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.802385 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.668572  [    0/60000]\n",
      "loss: 0.795513  [ 6400/60000]\n",
      "loss: 0.671767  [12800/60000]\n",
      "loss: 0.889795  [19200/60000]\n",
      "loss: 0.733735  [25600/60000]\n",
      "loss: 0.923013  [32000/60000]\n",
      "loss: 0.680869  [38400/60000]\n",
      "loss: 0.868869  [44800/60000]\n",
      "loss: 0.835378  [51200/60000]\n",
      "loss: 0.820440  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.784360 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.647398  [    0/60000]\n",
      "loss: 0.776899  [ 6400/60000]\n",
      "loss: 0.657400  [12800/60000]\n",
      "loss: 0.881559  [19200/60000]\n",
      "loss: 0.721601  [25600/60000]\n",
      "loss: 0.906015  [32000/60000]\n",
      "loss: 0.665668  [38400/60000]\n",
      "loss: 0.858874  [44800/60000]\n",
      "loss: 0.819643  [51200/60000]\n",
      "loss: 0.805065  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.770395 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.630993  [    0/60000]\n",
      "loss: 0.762062  [ 6400/60000]\n",
      "loss: 0.645262  [12800/60000]\n",
      "loss: 0.875619  [19200/60000]\n",
      "loss: 0.713493  [25600/60000]\n",
      "loss: 0.891996  [32000/60000]\n",
      "loss: 0.653804  [38400/60000]\n",
      "loss: 0.852567  [44800/60000]\n",
      "loss: 0.809946  [51200/60000]\n",
      "loss: 0.793259  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.759906 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.619047  [    0/60000]\n",
      "loss: 0.751471  [ 6400/60000]\n",
      "loss: 0.634739  [12800/60000]\n",
      "loss: 0.870262  [19200/60000]\n",
      "loss: 0.707519  [25600/60000]\n",
      "loss: 0.879654  [32000/60000]\n",
      "loss: 0.645614  [38400/60000]\n",
      "loss: 0.848575  [44800/60000]\n",
      "loss: 0.803028  [51200/60000]\n",
      "loss: 0.783915  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.751600 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.609416  [    0/60000]\n",
      "loss: 0.743857  [ 6400/60000]\n",
      "loss: 0.626180  [12800/60000]\n",
      "loss: 0.864840  [19200/60000]\n",
      "loss: 0.701984  [25600/60000]\n",
      "loss: 0.869398  [32000/60000]\n",
      "loss: 0.639972  [38400/60000]\n",
      "loss: 0.848078  [44800/60000]\n",
      "loss: 0.797732  [51200/60000]\n",
      "loss: 0.775676  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.744852 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.601084  [    0/60000]\n",
      "loss: 0.737433  [ 6400/60000]\n",
      "loss: 0.618815  [12800/60000]\n",
      "loss: 0.859231  [19200/60000]\n",
      "loss: 0.695167  [25600/60000]\n",
      "loss: 0.860400  [32000/60000]\n",
      "loss: 0.636483  [38400/60000]\n",
      "loss: 0.846217  [44800/60000]\n",
      "loss: 0.793372  [51200/60000]\n",
      "loss: 0.769051  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.739125 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.593760  [    0/60000]\n",
      "loss: 0.731718  [ 6400/60000]\n",
      "loss: 0.612363  [12800/60000]\n",
      "loss: 0.853406  [19200/60000]\n",
      "loss: 0.687753  [25600/60000]\n",
      "loss: 0.852447  [32000/60000]\n",
      "loss: 0.634049  [38400/60000]\n",
      "loss: 0.844890  [44800/60000]\n",
      "loss: 0.790186  [51200/60000]\n",
      "loss: 0.763928  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.734106 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.587258  [    0/60000]\n",
      "loss: 0.726706  [ 6400/60000]\n",
      "loss: 0.606598  [12800/60000]\n",
      "loss: 0.847935  [19200/60000]\n",
      "loss: 0.681442  [25600/60000]\n",
      "loss: 0.845375  [32000/60000]\n",
      "loss: 0.632318  [38400/60000]\n",
      "loss: 0.843886  [44800/60000]\n",
      "loss: 0.787267  [51200/60000]\n",
      "loss: 0.759040  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.729660 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.581336  [    0/60000]\n",
      "loss: 0.721933  [ 6400/60000]\n",
      "loss: 0.601334  [12800/60000]\n",
      "loss: 0.842754  [19200/60000]\n",
      "loss: 0.675065  [25600/60000]\n",
      "loss: 0.839356  [32000/60000]\n",
      "loss: 0.630742  [38400/60000]\n",
      "loss: 0.842458  [44800/60000]\n",
      "loss: 0.784791  [51200/60000]\n",
      "loss: 0.754779  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.725719 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.575754  [    0/60000]\n",
      "loss: 0.717394  [ 6400/60000]\n",
      "loss: 0.596357  [12800/60000]\n",
      "loss: 0.837818  [19200/60000]\n",
      "loss: 0.669078  [25600/60000]\n",
      "loss: 0.833628  [32000/60000]\n",
      "loss: 0.629304  [38400/60000]\n",
      "loss: 0.841740  [44800/60000]\n",
      "loss: 0.782129  [51200/60000]\n",
      "loss: 0.750932  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.722154 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.570425  [    0/60000]\n",
      "loss: 0.713697  [ 6400/60000]\n",
      "loss: 0.591944  [12800/60000]\n",
      "loss: 0.832958  [19200/60000]\n",
      "loss: 0.664020  [25600/60000]\n",
      "loss: 0.828658  [32000/60000]\n",
      "loss: 0.626530  [38400/60000]\n",
      "loss: 0.840636  [44800/60000]\n",
      "loss: 0.779705  [51200/60000]\n",
      "loss: 0.746809  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.718931 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"./model/101.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}